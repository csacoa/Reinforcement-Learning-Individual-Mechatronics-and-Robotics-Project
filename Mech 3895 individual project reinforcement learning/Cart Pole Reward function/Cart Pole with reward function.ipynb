{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dd07410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIRD REWARD FUNCTION\n",
    "\n",
    "import os\n",
    "import gym\n",
    "from stable_baselines3 import PPO, TD3, DDPG, A2C , DQN, SAC\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import numpy as np\n",
    "import time\n",
    "algorithm_name = \"PPO\"\n",
    "environment_name = 'CartPole-v1'\n",
    "#environment_names = ['CartPole-v1', 'Acrobot-v1',\n",
    "#'MountainCar-v0', 'MountainCarContinuous-v0', 'LunarLander-v2', \n",
    "#'BipedalWalker-v3', 'CarRacing-v0', Pendulum-v1]\n",
    "#\"BipedalWalker-v3\", hardcore=True to make bipedal hardcore environment\n",
    "env = gym.make(environment_name)\n",
    "\n",
    "\n",
    "#THIRD REWARD FUNCTION\n",
    "def new_reward_function(state, action, next_state):\n",
    "    # This should give us the current position of the cart\n",
    "    cart_position = state[0]\n",
    "\n",
    "    # This will define the reward as a sum of its position from the centre\n",
    "    reward = 1 - ((3*cart_position)**2)\n",
    "    return reward\n",
    "#THIRD REWARD FUNCTION\n",
    "\n",
    "\n",
    "env.reward_func = new_reward_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "202f6791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SECOND REWARD FUNCTION\n",
    "\n",
    "\n",
    "import os\n",
    "import gym\n",
    "from stable_baselines3 import PPO, TD3, DDPG, A2C , DQN, SAC\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import numpy as np\n",
    "import time\n",
    "algorithm_name = \"PPO\"\n",
    "environment_name = 'CartPole-v1'\n",
    "#environment_names = ['CartPole-v1', 'Acrobot-v1',\n",
    "#'MountainCar-v0', 'MountainCarContinuous-v0', 'LunarLander-v2', \n",
    "#'BipedalWalker-v3', 'CarRacing-v0', Pendulum-v1]\n",
    "#\"BipedalWalker-v3\", hardcore=True to make bipedal hardcore environment\n",
    "env = gym.make(environment_name)\n",
    "\n",
    "\n",
    "#SECOND REWARD FUNCTION\n",
    "def new_reward_function(state, action, next_state):\n",
    "    # This should give us the current position of the cart\n",
    "    cart_position = state[0]\n",
    "\n",
    "    # This will define the reward as a sum of its position from the centre\n",
    "    \n",
    "    if abs(cart_position) <= 0.1:\n",
    "        reward = 1\n",
    "    else:\n",
    "        reward = -0.1     \n",
    "    return reward\n",
    "#SECOND REWARD FUNCTION\n",
    "\n",
    "\n",
    "env.reward_func = new_reward_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a03f4bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIRST REWARD FUNCTION\n",
    "\n",
    "\n",
    "import os\n",
    "import gym\n",
    "from stable_baselines3 import PPO, TD3, DDPG, A2C , DQN, SAC\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import numpy as np\n",
    "import time\n",
    "algorithm_name = \"PPO\"\n",
    "environment_name = 'CartPole-v1'\n",
    "#environment_names = ['CartPole-v1', 'Acrobot-v1',\n",
    "#'MountainCar-v0', 'MountainCarContinuous-v0', 'LunarLander-v2', \n",
    "#'BipedalWalker-v3', 'CarRacing-v0', Pendulum-v1]\n",
    "#\"BipedalWalker-v3\", hardcore=True to make bipedal hardcore environment\n",
    "env = gym.make(environment_name)\n",
    "\n",
    "\n",
    "#FIRST REWARD FUNCTION\n",
    "def new_reward_function(state, action, next_state):\n",
    "    # This should give us the current position of the cart\n",
    "    cart_position = state[0]\n",
    "\n",
    "    # This will define the reward as a sum of its position from the centre\n",
    "    reward = 1 - abs(cart_position)\n",
    "    \n",
    "    return reward\n",
    "#FIRST REWARD FUNCTION\n",
    "\n",
    "\n",
    "env.reward_func = new_reward_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18beef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea17dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
